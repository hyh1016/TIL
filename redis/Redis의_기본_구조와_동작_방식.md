# Redis의 기본 구조와 동작 방식

## 왜 싱글 스레드인가?

- 무조건 멀티 스레드가 더 빠를까? 당연히 아님
- 멀티스레드가 더 효율적인 경우는 시간이 오래 걸리는 복잡한 연산 중심의 시스템이거나, I/O 중심의 시스템인 경우
- 단순한 연산이 주를 이루는 시스템의 경우에는 멀티 스레드 모델이 오히려 성능이 안 좋을 수 있음 (컨텍스트 스위칭 비용, 원자성 보장을 위한 Lock 사용 등에 의함)
- Redis는 인메모리 특성 상 데이터가 메모리에 있어 데이터의 생성/조회/수정 연산이 매우 빠르게 끝나기 때문에 싱글 스레드를 채택
- Redis 6.0부터는 I/O 작업은 멀티스레드로 처리할 수 있게 됨 (명령 처리 자체는 여전히 싱글 스레드로 동작)

## Redis의 동작 방식 - 이벤트 루프

- 여러 클라이언트와 연결하고 각각에 별도 스레드를 할당하는 대신 OS가 각 클라이언트 소켓에서 발생하는 이벤트를 감시하다가 이벤트가 도착하면 운영체제가 Redis에 시스템 콜(epoll/kqueue)을 통해 알림. Redis는 이 이벤트를 큐에 쌓고 순차 처리
    - Redis가 처리하는 이벤트는 File Event와 Time Event 2가지
        - File Event: 클라이언트 연결, 명령어 수신, 응답 전송 등의 Socket I/O Event
        - Time Event: 만료 키 삭제, AOF/RDB 비동기 데이터 영속화와 같은 주기적 작업
- 전통적 방식인 Thread-Per-Connection 방식의 경우 데이터가 도착할 때까지 스레드가 대기(Blocking)하며 리소스를 낭비하게 되는데, 레디스는 단일 스레드로 모든 클라이언트 이벤트를 처리해 리소스를 효율적으로 사용함

## Redis의 설계 원칙 - 메모리 최적화

- 레디스는 인메모리 데이터베이스이기 때문에 메모리를 최적화
- 자체 문자열 라이브러리 SDS를 사용
    - 문자열의 길이를 미리 저장해 문자열 길이 확인 시간 복잡도 O(1)
        - C 표준 라이브러리의 경우 O(N)
    - 문자열 길이를 미리 알고 있어 Binary-safe 하기 때문에 이미지/비디오 같은 바이너리 데이터도 저장 가능
    - 문자열에 문자가 추가될 때마다 메모리 공간을 할당하면 비효율적이기 때문에 공간이 부족해지면 최소 필요 공간의 2배로 늘리는 로직
- 메모리 효율적 인코딩 전략
    - 데이터 개수가 적을 때에는 캐시 효율적인 자료구조(Ziplist/Listpack)를, 데이터 개수가 많아지면 조회 성능이 효율적인 포인터 기반 자료구조(Hashtable)를 사용하는 등 데이터 크기에 따라 내부 구현체를 갈아끼움
- 객체 공유(Object Sharing)
    - 0~9999 범위 정수는 공유 객체로 관리하여 재사용함으로써 메모리 절약 (maxmemory-policy: LRU 설정 시 비활성화)

## Redis의 장점

- 초고속 성능: 인메모리 특성 상 평균 1ms 이하의 응답 속도 제공
- 다양한 자료구조: List, Hash, Set, Sorted Set, Streams 등 로직 구현에 효율적인 자료구조 제공
- 원자성 보장: 모든 명령어는 원자적으로 실행되어 동시성 보장 용이
- 복제 및 고가용성: Master-Replica 복제, Sentinel을 통한 자동 failover
- 클러스터링: Redis Cluster를 통한 수평 확장 (샤딩)

## Redis를 사용할 때 유의할 점

- 싱글 스레드이기 때문에, 고비용 명령어 사용에 유의해야 함
    - O(N) 시간복잡도를 갖는 `KEYS *`, `FLUSHALL`, 큰 데이터에 대한 `HGETALL`, `SMEMBERS`, `SORT`
    - 대신 `SCAN`, `HSCAN` 등을 통해 분할 처리해야 함
- 메모리가 부족해졌을 때 어떻게 동작할지 설정 및 인지하고 있어야 함
    - `maxmemory-policy` 라는 설정을 통해 관리하며 아래와 같은 옵션이 제공됨
        - `noeviction`: 메모리 부족 시 쓰기 거부 (기본값)
        - `allkeys-lru`: 모든 키 중 LRU 방식으로 제거
        - `volatile-lru`: TTL이 설정된 키만 LRU 방식으로 제거
        - `allkeys-lfu`: LFU(Least Frequently Used) 방식
- 메모리 파편화에 주의
    - Redis는 자체 메모리 할당자(ex: `jemalloc`)를 통해 데이터를 저장
    - 자체 할당자는 효율성을 위해 메모리를 고정 크기의 슬롯으로 관리
    - 고정 크기에서 저장이 필요한 데이터를 저장하고 남는 공간에 의해 내부 파편화가 발생
    - 남는 공간이 있음에도 더 큰 데이터를 저장해야 해서 새 페이지를 사용하다보면 기존 구멍이 빈 채로 남는 외부 파편화가 심화됨
    - `INFO memory` 명령을 통해 `mem_fragmentation_ratio` 지표를 모니터링해야 함
        $$\text{mem\_fragmentation\_ratio} = \frac{\text{used\_memory\_rss}}{\text{used\_memory}}$$
        - 1.0~1.2: 정상적인 상태 (실제 OS가 할당한 메모리가 약간 더 큼. 즉, 파편이 크지 않음)
        - 1.5 이상: 파편화가 심각해 메모리 낭비가 심각한 상태
        - 1.0 미만: OS 할당 메모리보다 Redis가 사용하는 메모리가 더 많다는 뜻으로, 물리 메모리 부족에 의한 디스크 스왑이 발생한 상태. 이 상태면 스와핑 발생에 의해 명령 처리 속도가 느려질 수 있음!
    - 그럼 파편화가 심할 때 어떻게 메모리를 관리? Redis 4.0부터 지원되는 `Active Defrag` 기능을 통해 Redis를 중지하지 않고 메모리 정리가 가능
    - 하지만 이 기능은 CPU 자원을 소모하기 때문에 CPU 사용량이 높은 상황이라면 이 기능을 활성화하는 것이 오히려 위험할 수도 있음
    - 어찌됐든 mem_fragmentation_ratio가 1.5를 넘어가면 알람이 오도록 설정하여 파편화에 대응해야 함
